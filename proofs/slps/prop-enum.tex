% !TeX spellcheck = en_US

\newcommand{\len}{\mathsf{len}}
\newcommand{\shift}{\mathsf{HEYHEYHEY}}

\begin{proof}
Let $\D = (\infAlph, V, \ell, r, \lambda)$ be a duplicate-free and $k$-bounded \dsabbr{}.
The algorithm that we present is a depth-first traversal of the DAG, done in a particular way to ensure that after retrieving some output, the next one can be found in $O(k\cdot \ell)$ time, where $\ell$ is the size of the latter. First, we will assume that the algorithm receives a duplicate-free and $k$-bounded $\cD$ and an output node $v$, and then we will extend it to the case where $v$ is a union node. The entire procedure (including the latter case) is detailed in Algorithm~\ref{slps:alg:enumeration}.

\input{../algorithms/enumalg}

As preliminaries, assume we have the native methods $\text{\sf push}$, $\text{\sf pop}$, $\text{\sf top}$, and $\text{\sf length}$ over stacks -- the first three define the standard operations over stacks, and $\text{\sf length}$ counts the elements in it, along with a native method $\text{\sf print}$ which receives a symbol $a\in\infAlph$ and prints it to a global output tape in constant time.

This algorithm prints the strings in $\sem{\cD}(v)$ in a certain order, and it does so via the subroutines $\pfirst(v)$, $\pcurr(v)$ which are defined only for a product or bottom node $v$, and $\pnext(v)$ which is only defined when $v$ is a product node.
The subroutine $\pfirst(v)$ prints the first string in $\sem{\cD}(v)$ according to the order, $\pnext(v)$ prints the next string to the previous one printed, and $\pcurr(v)$ prints the same string as the previous one. We assume that methods are called not over the nodes themselves but over node {\it instances} which are uniquely defined by the trace of nodes that start at the node on which the method {\sc Enumerate} was called. For example, if a node $v_1$ has $v_2$ and $v_3$ as children, and $v_2$ has $v_3$ as a child as well, calling $v_1$ instantiates $v_2$ and $v_3$, and this instance of $v_2$ instantiates a different copy of $v_3$. However, calling $v_1$ again instantiates the same copies of $v_2$ and $v_3$, and the copy of $v_3$ that stems from $v_2$ is the same as in the first time.

The subroutines utilize some global variables that depend on some node instance $v$. There is a flag $\text{\sf end}_v$ which indicates that the last string in $\sem{\cD}(v)$ was just printed, and stacks $St^{r}_v$ and $St^{\ell}_v$ which store the path of union nodes from $\ell(v)$ and $r(v)$ that reach the product of bottom node to be called in order to print the left and right halves of the current string. From this point on, we will refer to nodes and node instances  indistinctly as nodes.

We start by explaining the method $\text{\sc EnumerateAll}$ which is defined only for product and bottom nodes. The purpose of the method is to print the set $\sem{\cD}(v)$ exhaustively, and stop when $\text{\sf end}_v$ is set to true.

The method $\pfirst(v)$ behaves as expected: If $v$ is a bottom node it simply prints $\lambda(v)$, and if it is a product node, it creates two stacks which store the union nodes that can be reached from $\ell(v)$ and $r(v)$ by descending to the left until the product or bottom nodes $v_1$ and $v_2$ are reached. Then, it recursively prints the first strings in $\sem{\cD}(v_1)$ and $\sem{\cD}(v_2)$, in that order.

The method $\pcurr(v)$ is self-explanatory -- it prints the same string again.

Before explaining what $\pnext(v)$ does let us introduce the following concept: We sat that $u$ is a {\it descendant-through-unions} of a node $v$ if it is $v$ itself, or if $v$ is a union node, and $u$ is a descendant-through-unions of a child of $v$. Let $\text{\sf out}^{\ell}_v$ ($\text{\sf out}^{r}_v$) be the list of descendants-through-unions of $\ell(v)$ ($r(v)$) that are product of bottom nodes. As an example, in Figure~\ref{slps:fig-enum-stacks}, letting $v$ be the product node at the top, the list $\text{\sf out}^{r}_v$  is made of the nodes  $a_1,\ldots, a_6$ in that order.

The objective of method $\pnext(v)$ is that after calling $\pfirst(v)$, calling $\pnext(v)$ repeatedly until $\text{\sf end}_v$ is set to $\text{\bf true}$ results in printing the entire set $\sem{\cD}(v)$. To see how the algorithm does this, note that $\pfirst(v)$ sets the stacks $St^{\ell}_v$ and $St^{r}_v$ in a way that at the top sit the first nodes in $\text{\sf out}^{\ell}_v$ and $\text{\sf out}^{r}_v$ respectively. Lines~\ref{slps:alg:phase1a} through~\ref{slps:alg:phase1b} move the stacks in a way such that for every pair of nodes $v_1, v_2$, where $v_1\in\text{\sf out}^{\ell}_v$ and $v_2\in\text{\sf out}^{r}_v$, the stacks $St^{\ell}_v$ and $St^{r}_v$ will have nodes $v_1$ and $v_2$ at the top at some point, respectively. Lines~\ref{slps:alg:phase2a} through~\ref{slps:alg:phase2b} print the strings in $\sem{\cD}(v_1)$ and $\sem{\cD}(v_2)$ for each of these pairs.

Lastly, we elaborate on the purpose of auxiliary methods {\sc Traverse}$(v, St)$ and {\sc Move}$(St)$, which are used in the methods above. As can be seen,  {\sc Traverse}$(v, St)$ is used to descend through left-child union nodes until it sees a product or bottom node, and stores all seen nodes in stack $St$. At the end of it, the node at the top of $St$ is the leftmost descendant-through-unions from $v$ which is a product or bottom node. Then, {\sc Move}$(St)$ shifts the stack so it reaches the next of these descendants-through-unions, and while doing that, it removes the union node which is the least common ancestor of these two descendants-through-unions from $St$. This move allows the algorithm to navigate arbitrarily long chains of right-child union nodes and always need a constant number of steps (modulo $k$) to reach the next product or bottom node.

\begin{figure}[t]
	\centering
	\input{../figures/enumfigurenew.tex}
	\caption{Evolution of the stack ${\sf St}$ (represented by dashed arrows) for an iterator over the topmost union node in the figure. The underlying ECS contains only union nodes and six bottom nodes. The first figure is ${\sf St}$ after calling ${\sf St} \gets {\sf push}({\sf St}, v)$, the second is after calling ${\sf St} \gets\textsc{Traverse}({\sf St})$. The last two figures represent successive calls to ${\sf pop}({\sf St}), {\sf St} \gets\textsc{Traverse}({\sf St})$.}
	\label{nested:fig-enum-stacks}
\end{figure}

We shall prove that the algorithm works as expected. Recall that we are assuming that $v$ is a bottom or product node. Let $Pr(v)$ be the list of strings that are printed by calling $\pfirst(v)$ and then $\pnext(v)$ repeatedly until the flag $\text{\sf end}_v$ is set to {\bf true}. Our goal is to prove by induction that $Pr(v)$ contains no repeats and that its contents are exactly $\sem{\cD}(v)$. If $v$ is a bottom node, this is trivial. Assume now that $v$ is a product node and that this holds for every descendant of $v$ which is a product or bottom node. It is easy to check that $Pr(v)$ contains all the elements in $\sem{\cD}(v)$ by simple inspection of the algorithm. Now, towards a contradiction, suppose there is some repeated element in $Pr(v)$, and let $v^*$ be deepest descendant of $v$ for which $Pr(v^*)$ has a duplicate. This node cannot be $v$ itself because $\cD$ is assumed to be duplicate-free. Because of the inductive hypothesis, $v^*$ must be a descendant-through-unions of $v$ which is not a bottom or product node. Therefore, $v^*$ is a union node, and since $Pr(\ell(v^*))$ and $Pr(r(v^*))$ do not contain duplicates, it must be the case that they have an element in common, which contradicts the assumption that $\cD$ is duplicate-free.

%Proving that calling $\pfirst(v)$ and $\pnext(v)$ repeatedly until the flag $\text{\sf end}_v$ is set to {\bf true} prints the entire set $\sem{\cD}(v)$ is rather straightforward. If $v$ is a bottom node, this is trivial. If $v$ is a product node, consider some $w\in\sem{\cD}(v)$ and $w_1, w_2$ such that $w_1\in\sem{\cD}(\ell(v))$, $w_2\in\sem{\cD}(\ell(v))$ and $w_1\cdot w_2 = w$. It can be easily seen that $w_1\in\sem{\cD}(v_1)$ for some $v_1\in\text{\sf out}^{\ell}_v$ and that  $w_2\in\sem{\cD}(v_2)$ for some $v_2\in\text{\sf out}^{r}_v$. Note that by the construction of the algorithm, these nodes are reached in some execution of lines~\ref{slps:alg:phase1a} through~\ref{slps:alg:phase1b}, and that in lines~\ref{slps:alg:phase2a} through~\ref{slps:alg:phase2b} the methods  $\pfirst(v')$ and $\pnext(v')$ are called repeatedly until $\text{\sf end}_{v'}$ is set to {\bf true} for $v'\in\{v_1, v_2\}$. We recursively assume that the sets $\sem{\cD}(\ell(v))$ and $\sem{\cD}(r(v))$ are printed in their entirety through these methods, so we conclude that the string $w$ is printed at some point.

We shall prove the time bounds inductively. Note that {\sc Traverse}$(v, St)$ takes $O(k)$ time, and that this is the only iterative or recursive part in the {\sc Print} methods besides the calls to themselves. Assume now that any of these {\sc Print} methods takes $c\cdot(k+1)(|w| - 1) + c$ for some constant $c$, where $w$ is the string being printed. This holds trivially for a bottom node. Assume $k > 0$ and let $c$ be such that calling a {\sc Print} method over a product node takes $c\cdot k$ to perform the operations which are not recursively calling a {\sc Print} method. To measure the time taken by a {\sc Print} call method over $v$, let $w_1$ and $w_2$ be such that $w = w_1\cdot w_2$, and they are the strings printed by a recursive call over $v_1$ and $v_2$ respectively. These calls take time $c\cdot(k+1)(|w_1| - 1) + c$ and $c\cdot(k+1)(|w_2| - 1) + c$, respectively. Therefore, the entire call takes $c\cdot(k+1)(|w_1| + |w_2| - 2) + 2c + c\cdot k = c\cdot(k+1)(|w_1| + |w_2| - 2) + c + c\cdot(k+1) = c\cdot(k+1)(|w| - 1) + c$, which proves the inductive statement.
%To show the time bounds of this procedure, first we note the fact that each pair $(\oout, i)$ is printed directly so we do not take this time into account, as it only adds constant time per element in the output. Call $\len(w)$ the length of $w$, as in, the number of pairs $(\oout, i)$ in it. Let $c$ be the time needed to do the constant-time operations utilized in the algorithm, such as pushing and popping from the stack, navigating to some child of a node, etc. We inductively assume that for any product or bottom node $u$, a call to $\pfirst(u, s)$ to $\pnext(u, s)$ and $\pcurr(u, s)$ each take at most $2c\cdot (k+2)\cdot (\len(w)-1)$ time, where $w$ is the output produced. Note that this follows trivially for a bottom node.
%For a product node $v$, the call $\pfirst(v, s)$ takes time at most $c\cdot 2(k+1)$ to build the stacks $St_1$ and $St_2$, and then $2c\cdot (k+2)\cdot (\len(w_1^*) + \len(w_2^*) - 2)$ to call $\pfirst(v_1, s')$ and $\pfirst(v_2, s'')$, which print $w_1^*$ and $w_2^*$ respectively. Therefore, by using that $\len(w^*) = \len(w_1^*) + \len(w_2)$ the call to $\pfirst(v)$ takes time at most $2c\cdot (k+2)\cdot (\len(w^*)-1)$. For the call $\pnext(v, s)$, we have to account for several cases, but we simply note that the case which uses the most operations besides the calls to $v_1$ and $v_2$ is the one where both previous calls to $v_1$ and $v_2$ returned ${\tt end}$, and $St_2$ has only one node. In this case ${\tt move}(St_1)$ has to be called, and $St_1\gets {\tt trav}(r(v))$ has to be called, which take at most time $c(k+2)$ and $c(k+1)$ respectively. Adding this time to the time needed to make a call to $v_1$ and $v_2$ gives a total time at most $2c\cdot (k+2)\cdot (\len(w^*)-1)$. 
We conclude that $\sem{\cD}(v)$ is enumerated with output-linear delay.

Finally, we refer to the case in which the method {\sc Enumerate}$(v)$ is done over a union node $v$. This is done by going over the descendants-through-unions of $v$ which are product or bottom nodes in a very similar fashion as it is done in the {\sc PrintNext} method. This adds a constant time $c\cdot k$ to produce each output, which maintains the output-linear delay bound we showed. This completes the proof. \end{proof}